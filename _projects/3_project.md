---
layout: page
title: Needle
description: NEcessary Elements of Deep LEarning
img: assets/img/needle_cover.webp
importance: 3
category: course
---

## Overview

The Needle project was a key part of my journey in understanding machine learning systems. This course project involved building a minimalistic deep learning framework from scratch, providing hands-on experience in implementing the core functionalities of deep learning libraries like PyTorch and TensorFlow. Through Needle, I delved into the fundamental concepts of automatic differentiation, neural network layers, and optimization techniques.

## Key Features

- **Automatic Differentiation**: Implemented a basic automatic differentiation framework that supports both forward and backward propagation, enabling the computation of gradients required for training neural networks.
- **Neural Network Building Blocks**: Developed essential neural network components such as Linear layers, ReLU activation functions, and BatchNorm layers, forming the core of the framework.
- **Optimizers**: Integrated optimization algorithms like Stochastic Gradient Descent (SGD) and Adam to facilitate efficient model training.
- **Data Handling**: Built data pipelines for efficient data loading and preprocessing, supporting transformations such as random flips and crops for image data.
- **CPU and GPU Backend Support**: Implemented support for NDArray operations on both CPU and GPU backends, allowing for performance optimization and scalability.

## Learning Outcomes

This project significantly enhanced my understanding of the internal mechanics of deep learning frameworks. By building Needle from the ground up, I gained deep insights into the challenges of creating efficient and scalable machine learning systems. This hands-on experience solidified my knowledge of key machine learning concepts and sharpened my skills in both software engineering and performance optimization.
